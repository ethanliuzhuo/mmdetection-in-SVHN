{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9601f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import mmseg\n",
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette\n",
    "config_file = '/home/mmsegmentation/configs/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes.py'\n",
    "checkpoint_file = '/home/mmsegmentation/checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n",
    "\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_segmentor(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "# test a single image\n",
    "img = '/home/mmsegmentation/demo/demo.png'\n",
    "result = inference_segmentor(model, img)\n",
    "\n",
    "# show the results\n",
    "show_result_pyplot(model, img, result, get_palette('cityscapes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the dataset\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = mmcv.imread('data/house2/images/1A4O4TGL19.jpg')\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96388914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from concurrent import futures\n",
    "\n",
    "# convert dataset annotation to semantic segmentation map\n",
    "data_root = 'data/house2'\n",
    "img_dir = 'images'\n",
    "ann_dir = 'labels'\n",
    "# define class and plaette for better visualization\n",
    "classes = ('backgrade', 'house')\n",
    "palette = [[0, 0, 0], [255, 255, 255]]\n",
    "\n",
    "def save_png(file):\n",
    "      seg_map = np.loadtxt(osp.join(data_root, ann_dir, file)).astype(np.uint8)\n",
    "      seg_img = Image.fromarray(seg_map).convert('P')\n",
    "      seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "      seg_img.save(osp.join(data_root, ann_dir, file.replace('.txt','.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aee6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, results = [], []\n",
    "with futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    for file in tqdm(mmcv.scandir(osp.join(data_root, ann_dir), suffix='.txt')):\n",
    "        tasks.append(executor.submit(save_png, file))\n",
    "    for task in tqdm(futures.as_completed(tasks), total=len(tasks)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99591227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# convert dataset annotation to semantic segmentation map\n",
    "data_root = 'data/house2'\n",
    "img_dir = 'images'\n",
    "ann_dir = 'labels'\n",
    "# define class and plaette for better visualization\n",
    "classes = ('backgrade', 'house')\n",
    "palette = [[0, 0, 0], [255, 255, 255]]\n",
    "\n",
    "def save_png(file):\n",
    "      seg_map = np.loadtxt(osp.join(data_root, ann_dir, file)).astype(np.uint8)\n",
    "      seg_img = Image.fromarray(seg_map).convert('P')\n",
    "      seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "      seg_img.save(osp.join(data_root, ann_dir, file.replace('.txt','.png')))\n",
    "    \n",
    "for file in tqdm(mmcv.scandir(osp.join(data_root, ann_dir), suffix='.txt')):\n",
    "      seg_map = np.loadtxt(osp.join(data_root, ann_dir, file)).astype(np.uint8)\n",
    "      seg_img = Image.fromarray(seg_map).convert('P')\n",
    "      seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "      seg_img.save(osp.join(data_root, ann_dir, file.replace('.txt', \n",
    "                                                         '.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c7d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the segmentation map we got\n",
    "import matplotlib.patches as mpatches\n",
    "img = Image.open('data/house2/labels/1A4O4TGL19.png')\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(np.array(img.convert('RGB')))\n",
    "\n",
    "# create a patch (proxy artist) for every color \n",
    "patches = [mpatches.Patch(color=np.array(palette[i])/255., \n",
    "                          label=classes[i]) for i in range(2)]\n",
    "# put those patched as legend-handles into the legend\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., \n",
    "           fontsize='large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8fa845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train/val set randomly\n",
    "split_dir = 'splits'\n",
    "mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n",
    "filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
    "    osp.join(data_root, ann_dir), suffix='.png')]\n",
    "with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n",
    "  # select first 4/5 as train set\n",
    "    train_length = int(len(filename_list)*29/30)\n",
    "    f.writelines(line + '\\n' for line in filename_list[:train_length])\n",
    "with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
    "  # select last 1/5 as train set\n",
    "    f.writelines(line + '\\n' for line in filename_list[train_length:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "# convert dataset annotation to semantic segmentation map\n",
    "data_root = 'data/house2'\n",
    "img_dir = 'test_a'\n",
    "ann_dir = 'labels'\n",
    "# define class and plaette for better visualization\n",
    "classes = ('backgrade', 'house')\n",
    "palette = [[0, 0, 0], [255, 255, 255]]\n",
    "split_dir = 'splits'\n",
    "mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n",
    "print(osp.join(data_root, split_dir))\n",
    "print(osp.join(data_root, ann_dir))\n",
    "\n",
    "filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
    "    osp.join(data_root, img_dir), suffix='.jpg')]\n",
    "\n",
    "with open(osp.join(data_root, split_dir, 'test.txt'), 'w') as f:\n",
    "  # select last 1/5 as train set\n",
    "    f.writelines(line + '\\n' for line in filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b7c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class StandfordBackgroundDataset(CustomDataset):\n",
    "  CLASSES = classes\n",
    "  PALETTE = palette\n",
    "  def __init__(self, split, **kwargs):\n",
    "    super().__init__(img_suffix='.jpg', seg_map_suffix='.png', \n",
    "                     split=split, **kwargs)\n",
    "    assert osp.exists(self.img_dir) and self.split is not None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2e9b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('configs/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f171f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import set_random_seed\n",
    "\n",
    "# Since we use ony one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 2\n",
    "cfg.model.auxiliary_head.num_classes = 2\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'StandfordBackgroundDataset'\n",
    "cfg.data_root = data_root\n",
    "\n",
    "cfg.data.samples_per_gpu = 8\n",
    "cfg.data.workers_per_gpu=8\n",
    "\n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "cfg.crop_size = (256, 256)\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(320, 240),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.img_dir = img_dir\n",
    "cfg.data.train.ann_dir = ann_dir\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = 'splits/train.txt'\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.img_dir = img_dir\n",
    "cfg.data.val.ann_dir = ann_dir\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = 'splits/val.txt'\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "cfg.data.test.img_dir = img_dir\n",
    "cfg.data.test.ann_dir = ann_dir\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'splits/val.txt'\n",
    "\n",
    "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
    "# use the mask branch\n",
    "cfg.load_from = '/home/mmsegmentation/checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './work_dirs/tutorial'\n",
    "\n",
    "cfg.runner.max_iters = 200\n",
    "cfg.log_config.interval = 10\n",
    "cfg.evaluation.interval = 200\n",
    "cfg.checkpoint_config.interval = 200\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973d1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "# Build the detector\n",
    "model = build_segmentor(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe22e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
    "                meta=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d24fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mmcv.imread('data/house2/images/1A4O4TGL19.jpg')\n",
    "\n",
    "model.cfg = cfg\n",
    "result = inference_segmentor(model, img)\n",
    "plt.figure(figsize=(8, 6))\n",
    "show_result_pyplot(model, img, result, palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e208cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = Image.open('data/house2/labels/1A7173V2GB.png')\n",
    "img2 = Image.open('data/house2/images/1A7173V2GB.jpg')\n",
    "img3 = Image.open('data/iccv09Data/labels/0000047.png')\n",
    "img4 = Image.open('data/iccv09Data/images/0000047.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65dc842",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img1.size)\n",
    "print(img2.size)\n",
    "print(img3.size)\n",
    "print(img4.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = mmcv.imread('data/house2/labels/1A7173V2GB.png')\n",
    "img2 = mmcv.imread('data/house2/images/1A7173V2GB.jpg')\n",
    "img3 = mmcv.imread('data/iccv09Data/labels/0000047.png')\n",
    "img4 = mmcv.imread('data/iccv09Data/images/0000047.jpg')\n",
    "\n",
    "print(img1.shape)\n",
    "print(img2.shape)\n",
    "print(img3.shape)\n",
    "print(img4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e781ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "\n",
    "img1 = mpimg.imread('data/house2/labels/1AXLWAONTR.png')\n",
    "img2 = mpimg.imread('data/house2/images/1AXLWAONTR.jpg')\n",
    "img3 = mpimg.imread('data/iccv09Data/labels/0000047.png')\n",
    "img4 = mpimg.imread('data/iccv09Data/images/0000047.jpg')\n",
    "\n",
    "print(img1.shape)\n",
    "print(img2.shape)\n",
    "print(img3.shape)\n",
    "print(img4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6846168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46b3c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1[:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf30c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "      seg_map = np.loadtxt(osp.join(data_root, ann_dir, file)).astype(np.uint8)\n",
    "      seg_img = Image.fromarray(seg_map).convert('P')\n",
    "      seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "      seg_img.save(osp.join(data_root, ann_dir, file.replace('.txt', \n",
    "                                                         '.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cbaa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# 将rle格式进行解码为图片\n",
    "def rle_decode(mask_rle, shape=(512, 512)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape, order='F')\n",
    "#train_mask = pd.read_csv('/home/mmsegmentation/data/VOCdevkit/train_mask.csv', sep='\\t', names=['name', 'mask'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_mask['mask'].iloc[4745]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(512*512, dtype=np.uint8)\n",
    "mask.reshape((512, 512), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b84ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask['name'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda06ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "len(os.listdir('data/house2/labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e088df",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('data/house2/images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17bd72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('data/VOCdevkit/label/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(os.listdir('data/VOCdevkit/label/'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f1584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "train_mask = pd.read_csv('/home/mmsegmentation/data/VOCdevkit/train_mask.csv', sep='\\t', names=['name', 'mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_mask['mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter   #引入Counter\n",
    "\n",
    "b = dict(Counter((os.listdir('data/VOCdevkit/label/'))))\n",
    "[key for key,value in b.items()if value > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d5485",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = os.listdir('data/VOCdevkit/label/')\n",
    "a.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from concurrent import futures\n",
    "\n",
    "def out_txt(i):\n",
    "    try:\n",
    "        mask = rle_decode(train_mask['mask'].iloc[i])\n",
    "    except:\n",
    "        mask = np.zeros(512*512, dtype=np.uint8)\n",
    "        mask = mask.reshape((512, 512), order='F')\n",
    "\n",
    "        path_txt = 'data/VOCdevkit/label2/' +  train_mask['name'].iloc[i].split('.')[0] + '.txt'\n",
    "        np.savetxt(path_txt,mask, fmt=\"%i\",delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, results = [], []\n",
    "with futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    for i in range(len(train_mask)):\n",
    "        tasks.append(executor.submit(out_txt, i))\n",
    "    for task in tqdm(futures.as_completed(tasks), total=len(tasks)):\n",
    "        results.append(task.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5cee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# convert dataset annotation to semantic segmentation map\n",
    "data_root = 'data/house2'\n",
    "img_dir = 'images'\n",
    "ann_dir = 'labels'\n",
    "# define class and plaette for better visualization\n",
    "classes = ('backgrade', 'house')\n",
    "palette = [[0, 0, 0], [255, 255, 255]]\n",
    "\n",
    "def save_png(file):\n",
    "      seg_map = np.loadtxt(osp.join(data_root, ann_dir, file)).astype(np.uint8)\n",
    "      seg_img = Image.fromarray(seg_map).convert('P')\n",
    "      seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "      seg_img.save(osp.join(data_root, ann_dir, file.replace('.txt','.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e878f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, results = [], []\n",
    "with futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    for file in tqdm(mmcv.scandir(osp.join(data_root, ann_dir), suffix='.txt')):\n",
    "        tasks.append(executor.submit(save_png, file))\n",
    "    for task in tqdm(futures.as_completed(tasks), total=len(tasks)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb441714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('house2_2/result.pkl','rb')\n",
    "data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ded662",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5cfd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = []\n",
    "name = []\n",
    "for i,image in enumerate(data):\n",
    "    rle = rle_encode(image.astype('uint8'))\n",
    "    mask += [rle]\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "test_mask = pd.read_csv('data/VOCdevkit/test_a_samplesubmit.csv',sep='\\t',names = ['name','mask'])\n",
    "\n",
    "name = test_mask['name'] \n",
    "\n",
    "df['name'] = name\n",
    "mask_all = ['' for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1545b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list[i] + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffdf043",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mask)):\n",
    "    ind  = df[df.name==filename_list[i]+ '.jpg'].index[0]\n",
    "    mask_all[ind] = mask[i]\n",
    "df['mask'] = mask_all\n",
    "\n",
    "df.to_csv('data/house2/test_b.csv',encoding='utf-8',header = None,index=False,sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0141fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the segmentation map we got\n",
    "import matplotlib.patches as mpatches\n",
    "img = Image.open('data/house2/labels/1A4O4TGL19.png')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(np.array(img.convert('RGB')))\n",
    "\n",
    "# create a patch (proxy artist) for every color \n",
    "#patches = [mpatches.Patch(color=np.array(palette[i])/255., \n",
    "#                          label=classes[i]) for i in range(2)]\n",
    "# put those patched as legend-handles into the legend\n",
    "#plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., \n",
    "#           fontsize='large')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f50f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_img = Image.fromarray(data[0].astype('uint8')).convert('P')\n",
    "seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "seg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac31ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_map = np.loadtxt('data/house/labels/label/0A3B10OZ9S.txt').astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebe36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "len(os.listdir('data/house2/images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f18a9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
